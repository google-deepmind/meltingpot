{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C02UCHvxwh8c"
      },
      "source": [
        "```\n",
        "Copyright 2022 DeepMind Technologies Limited.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HWpgjkuv1fH"
      },
      "source": [
        "# Melting Pot Evaluation Results\n",
        "\n",
        "\u003ca href=\"https://colab.research.google.com/github/google-deepmind/meltingpot/blob/main/notebooks/evaluation_results.ipynb\"\u003e\n",
        "\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\n",
        "\u003c/a\u003e\n",
        "\n",
        "This Colab plots results of the MAPLA evaluations outlined in the [Melting Pot 2.0 Tech Report](https://arxiv.org/abs/2211.13746).\n",
        "\n",
        "1.  Click \"Connect\" in the top right corner.\n",
        "2.  Select \"Runtime -\u003e Run all\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IxxEhtumBUKO"
      },
      "outputs": [],
      "source": [
        "# @title Installs\n",
        "\n",
        "%pip install --quiet colabtools\n",
        "%pip install --quiet matplotlib\n",
        "%pip install --quiet numpy\n",
        "%pip install --quiet pandas\n",
        "%pip install --quiet seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e1gcvGOjMY6"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XcuVeMOyZgSH"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "import dataclasses\n",
        "import re\n",
        "import sys\n",
        "from unittest import mock\n",
        "import urllib\n",
        "\n",
        "import IPython\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mabOJPluAhJE"
      },
      "outputs": [],
      "source": [
        "# @title Setup\n",
        "\n",
        "def no_vertical_scrollbar():\n",
        "  \"\"\"Disable scroll-in-the-scroll.\"\"\"\n",
        "  javascript = 'google.colab.output.setIframeHeight(0, true, {interactive: true, maxHeight: 9999})'\n",
        "  display(IPython.display.Javascript(javascript))\n",
        "\n",
        "\n",
        "# No vertical scrollbars.\n",
        "get_ipython().events.register('pre_run_cell', no_vertical_scrollbar)\n",
        "\n",
        "# Allow higher resolution plots.\n",
        "IPython.display.set_matplotlib_formats('retina')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-qiw4ao-UgXT"
      },
      "outputs": [],
      "source": [
        "# @title Utilities\n",
        "\n",
        "def display(dataframe):\n",
        "  \"\"\"Displays dataframe, regardless of size.\n",
        "\n",
        "  Args:\n",
        "    dataframe: dataframe to display.\n",
        "  \"\"\"\n",
        "  with pd.option_context('display.max_rows', None, 'display.max_columns', None,\n",
        "                         'display.max_colwidth', None):\n",
        "    IPython.display.display(dataframe)\n",
        "\n",
        "\n",
        "def _heatmap(data, **kwargs):\n",
        "  \"\"\"Plots a heatmap of the data.\n",
        "\n",
        "  Args:\n",
        "    data: Data to plot\n",
        "    **kwargs: forwarded to sns.heatmap\n",
        "\n",
        "  Returns:\n",
        "    The axes of the heatmap.\n",
        "  \"\"\"\n",
        "  max_abs_value = np.nanmax(np.abs(data))\n",
        "  kwargs.setdefault('cbar', False)\n",
        "  kwargs.setdefault('linewidth', 1)\n",
        "  kwargs.setdefault('annot', True)\n",
        "  if max_abs_value \u003e= 10000:\n",
        "    kwargs.setdefault('fmt', '.1g')\n",
        "  elif max_abs_value \u003e= 100:\n",
        "    kwargs.setdefault('fmt', '.0f')\n",
        "  elif max_abs_value \u003e= 10:\n",
        "    kwargs.setdefault('fmt', '.1f')\n",
        "  else:\n",
        "    kwargs.setdefault('fmt', '.2f')\n",
        "\n",
        "  ax = sns.heatmap(data, **kwargs)\n",
        "  plt.tick_params(\n",
        "      which='both', left=False, right=False, bottom=False, top=False)\n",
        "  plt.setp([tick.label1 for tick in ax.xaxis.get_major_ticks()],\n",
        "           rotation=45,\n",
        "           ha='right',\n",
        "           va='center',\n",
        "           rotation_mode='anchor')\n",
        "  plt.setp([tick.label2 for tick in ax.xaxis.get_major_ticks()],\n",
        "           rotation=45,\n",
        "           ha='left',\n",
        "           va='center',\n",
        "           rotation_mode='anchor')\n",
        "  return ax\n",
        "\n",
        "\n",
        "def heatmap(data, left=None, right=None, top=None, bottom=None, **kwargs):\n",
        "  row_labels = list(data.index)\n",
        "  col_labels = list(data.columns)\n",
        "  data = data.to_numpy()\n",
        "\n",
        "  if top is None:\n",
        "    top_rows = 0\n",
        "  elif not top.empty:\n",
        "    row_labels = list(top.index) + [''] + row_labels\n",
        "    data = np.vstack([\n",
        "        top.to_numpy(),\n",
        "        np.zeros(top.iloc[0].shape) + np.nan,\n",
        "        data,\n",
        "    ])\n",
        "    top_rows = top.shape[0] + 1\n",
        "\n",
        "  if bottom is None:\n",
        "    bottom_rows = 0\n",
        "  elif not bottom.empty:\n",
        "    row_labels = row_labels + [''] + list(bottom.index)\n",
        "    data = np.vstack([\n",
        "        data,\n",
        "        np.zeros(bottom.iloc[0].shape) + np.nan,\n",
        "        bottom.to_numpy(),\n",
        "    ])\n",
        "    bottom_rows = bottom.shape[0] + 1\n",
        "\n",
        "  if left is None:\n",
        "    pass\n",
        "  elif not left.empty:\n",
        "    col_labels = list(left.columns) + [''] + col_labels\n",
        "    data = np.hstack([\n",
        "        np.vstack([\n",
        "            np.zeros([top_rows, left.shape[1]]) + np.nan,\n",
        "            left.to_numpy(),\n",
        "            np.zeros([bottom_rows, left.shape[1]]) + np.nan,\n",
        "        ]),\n",
        "        np.zeros([data.shape[0], 1]) + np.nan,\n",
        "        data,\n",
        "    ])\n",
        "\n",
        "  if right is None:\n",
        "    pass\n",
        "  elif not top.empty:\n",
        "    col_labels = col_labels + [''] + list(right.columns)\n",
        "    data = np.hstack([\n",
        "        data,\n",
        "        np.zeros([data.shape[0], 1]) + np.nan,\n",
        "        np.vstack([\n",
        "            np.zeros([top_rows, right.shape[1]]) + np.nan,\n",
        "            right.to_numpy(),\n",
        "            np.zeros([bottom_rows, right.shape[1]]) + np.nan,\n",
        "        ]),\n",
        "    ])\n",
        "\n",
        "  with plt.rc_context({\n",
        "      'font.size': 15,\n",
        "      'xtick.labeltop': True,\n",
        "      'xtick.labelbottom': True,\n",
        "      'ytick.labelleft': True,\n",
        "      'ytick.labelright': True,\n",
        "  }):\n",
        "    plt.figure(figsize=(data.shape[1], data.shape[0] * 0.6))\n",
        "    kwargs.setdefault('vmin', 0)\n",
        "    kwargs.setdefault('vmax', 1)\n",
        "    kwargs.setdefault('cmap', 'coolwarm')\n",
        "    return _heatmap(\n",
        "        data=data,\n",
        "        xticklabels=col_labels,\n",
        "        yticklabels=row_labels,\n",
        "        **kwargs,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E7Uv5OCi8l9"
      },
      "source": [
        "## Fetch results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F7wd3g6IR8-t"
      },
      "outputs": [],
      "source": [
        "# @title Load scenario results\n",
        "path = 'https://storage.googleapis.com/dm-meltingpot/meltingpot-results-2.3.0.feather'  # @param {type: 'string'}\n",
        "\n",
        "def load_scenario_results(path):\n",
        "  results = pd.read_feather(path)\n",
        "  # Drop training scores\n",
        "  scenario_results = results.drop(\n",
        "      labels=set(results.substrate.unique()),\n",
        "      axis=1,\n",
        "      errors='ignore')\n",
        "  return scenario_results.set_index(['scenario', 'substrate', 'mapla', 'training_run'])\n",
        "\n",
        "\n",
        "scenario_results = load_scenario_results(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1v0rvkuW0C7p"
      },
      "outputs": [],
      "source": [
        "# @title Make assumptions about missing prosocial runs\n",
        "\n",
        "print(\"\"\"\n",
        "NOTE: For the collective-return substrates, the prosocial MAPLA receive rewards\n",
        "identical to those received by a non-prosocial variants (except for a scale\n",
        "factor). Thus, for these substrates, the prosocial MAPLA is identical to the\n",
        "non-prosocial variant, and we expect they would therefore achieved the same\n",
        "performance. We therefore copy the non-prosocial scores for this situation.\n",
        "\"\"\")\n",
        "\n",
        "_COLLECTIVE_RETURN_SUBSTATES = frozenset({\n",
        "    'collaborative_cooking__asymmetric',\n",
        "    'collaborative_cooking__circuit',\n",
        "    'collaborative_cooking__cramped',\n",
        "    'collaborative_cooking__crowded',\n",
        "    'collaborative_cooking__figure_eight',\n",
        "    'collaborative_cooking__forced',\n",
        "    'collaborative_cooking__ring',\n",
        "})\n",
        "\n",
        "\n",
        "def add_prosocial_performance(results):\n",
        "  df = results.reset_index()\n",
        "  df = df[df.substrate.isin(_COLLECTIVE_RETURN_SUBSTATES)]\n",
        "  df = df[df.mapla.isin(['acb', 'opre'])]\n",
        "  df = df.assign(mapla=df.mapla.map(lambda x: x + '_prosocial'))\n",
        "  df = df.set_index(['scenario', 'substrate', 'mapla', 'training_run'])\n",
        "  return pd.concat([results, df]).sort_index()\n",
        "\n",
        "\n",
        "scenario_results = add_prosocial_performance(scenario_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "53SNJ7_ALkEu"
      },
      "outputs": [],
      "source": [
        "# @title Keep only best exploiter for each scenario\n",
        "\n",
        "def keep_best_exploiter(scenario_results):\n",
        "  df = scenario_results.reset_index()\n",
        "  idx = df.mapla.map(lambda x: x.startswith('exploiter_'))\n",
        "  exploiters = df[idx]\n",
        "  non_exploiters = df[~idx]\n",
        "\n",
        "  performance = exploiters.groupby(['scenario', 'substrate', 'mapla']).focal_per_capita_return.max()\n",
        "  best_exploiter = performance.unstack('mapla').idxmax(axis=1)\n",
        "\n",
        "  idx = exploiters.apply(lambda row: best_exploiter.loc[row.scenario, row.substrate] == row.mapla, axis=1)\n",
        "  exploiters = exploiters[idx].assign(mapla='exploiter')\n",
        "\n",
        "  recombined = pd.concat([non_exploiters, exploiters])\n",
        "  return recombined.set_index(['scenario', 'substrate', 'mapla', 'training_run']).sort_index()\n",
        "\n",
        "\n",
        "scenario_results = keep_best_exploiter(scenario_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stuzqe8KFYmQ"
      },
      "source": [
        "## Calculate scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "m76CSuuNKX__"
      },
      "outputs": [],
      "source": [
        "# @title Normalize focal_per_capita_return statistics\n",
        "\n",
        "def normalize(performance_per_run):\n",
        "  raw = performance_per_run.unstack(['mapla', 'training_run'])\n",
        "  lower = raw.min(axis=1) - 1e-8\n",
        "  upper = raw.max(axis=1)\n",
        "  scale = upper - lower\n",
        "\n",
        "  normalized = raw.subtract(lower, axis=0).divide(scale, axis=0)\n",
        "  normalized = normalized.stack(['mapla', 'training_run'])\n",
        "  normalized = normalized.sort_index()\n",
        "  normalized.name = 'score'\n",
        "  return normalized\n",
        "\n",
        "\n",
        "scenario_scores_per_run = normalize(scenario_results.focal_per_capita_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1JnIN6yiYZ0w"
      },
      "outputs": [],
      "source": [
        "# @title Calculate per-substrate scores\n",
        "\n",
        "def get_substrate_scores_per_run(scenario_scores_per_run):\n",
        "  grouped = scenario_scores_per_run.groupby(['substrate', 'mapla', 'training_run'])\n",
        "  scenarios_per_substrate = grouped.count().groupby('substrate').max()\n",
        "  substrate_scores_per_run = grouped.sum() / scenarios_per_substrate\n",
        "  substrate_scores_per_run.name = 'score'\n",
        "  return substrate_scores_per_run\n",
        "\n",
        "\n",
        "substrate_scores_per_run = get_substrate_scores_per_run(scenario_scores_per_run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R1ZgicDs3zqL"
      },
      "outputs": [],
      "source": [
        "# @title Calculate overall scores\n",
        "\n",
        "def get_overall_scores_per_run(substrate_scores_per_run):\n",
        "  grouped = substrate_scores_per_run.groupby(['mapla', 'training_run'])\n",
        "  substrates = grouped.count().max()\n",
        "  overall_scores_per_run = grouped.sum() / substrates\n",
        "  overall_scores_per_run.name = 'score'\n",
        "  return overall_scores_per_run\n",
        "\n",
        "\n",
        "overall_scores_per_run = get_overall_scores_per_run(substrate_scores_per_run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K9SdhF0FcXe"
      },
      "source": [
        "## Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fXRcA1ketAqn"
      },
      "outputs": [],
      "source": [
        "# @title Plot scores\n",
        "\n",
        "def plot_scores(scenario_scores_per_run, substrate_scores_per_run, overall_scores_per_run):\n",
        "  overall_scores = overall_scores_per_run.groupby(['mapla']).mean()\n",
        "  overall_scores = overall_scores.sort_values(ascending=False)\n",
        "\n",
        "  substrate_scores = substrate_scores_per_run.groupby(['substrate', 'mapla']).mean()\n",
        "  substrate_scores = substrate_scores.unstack('mapla')\n",
        "  substrate_scores = substrate_scores.reindex(columns=overall_scores.index)\n",
        "\n",
        "  scenario_scores = scenario_scores_per_run.groupby(['scenario', 'substrate', 'mapla']).mean()\n",
        "  scenario_scores = scenario_scores.unstack('mapla')\n",
        "  scenario_scores = scenario_scores.reindex(columns=overall_scores.index)\n",
        "\n",
        "  tabs = widgets.TabBar(['summary', 'breakdown'])\n",
        "\n",
        "  with tabs.output_to('summary'):\n",
        "    top = pd.DataFrame.from_dict({'overall score': overall_scores}, orient='index')\n",
        "    heatmap(substrate_scores, top=top)\n",
        "\n",
        "  with tabs.output_to('breakdown', select=False):\n",
        "    substrates = scenario_scores.index.unique('substrate')\n",
        "    subtabs = widgets.TabBar(sorted(substrates))\n",
        "    for substrate, df in scenario_scores.groupby(level='substrate'):\n",
        "      with subtabs.output_to(substrate, select=False):\n",
        "        df = df.droplevel('substrate')\n",
        "\n",
        "        top = pd.DataFrame.from_dict({\n",
        "            'all substrates': overall_scores,\n",
        "            substrate: substrate_scores.loc[substrate]\n",
        "        }, orient='index')\n",
        "        heatmap(df, top=top)\n",
        "\n",
        "\n",
        "\n",
        "plot_scores(scenario_scores_per_run, substrate_scores_per_run, overall_scores_per_run)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_e1gcvGOjMY6",
        "6E7Uv5OCi8l9",
        "stuzqe8KFYmQ"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
